{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "\n",
    "#col_Names=[\"Class\", \"AGE\", \"SEX\", \"STEROID\",\"ANTIVIRALS\", \"FATIGUE\", \"MALAISE\", \"ANOREXIA\",\"LIVER BIG\", \"LIVER FIRM\", \"SPLEEN PALPABLE\", \"SPIDERS\",\"ASCITES\", \"VARICES\", \"ALK PHOSPHATE\",\"BILIRUBIN\", \"SGOT\",\"ALBUMIN\", \"PROTIME\", \"HISTOLOGY\"]\n",
    "data = pd.read_csv('C:/Users/moizadamjee/Desktop/Uzair/hepatitas/hepatitis.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head()\n",
    "df = data.coppy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['steroid'].fillna(df['steroid'].mode()[0], inplace = True)\n",
    "df['fatigue'].fillna(df['fatigue'].mode()[0], inplace = True)\n",
    "df['malaise'].fillna(df['malaise'].mode()[0], inplace = True)\n",
    "df['anorexia'].fillna(df['anorexia'].mode()[0], inplace = True)\n",
    "df['liver_big'].fillna(df['liver_big'].mode()[0], inplace = True)\n",
    "df['liver_firm'].fillna(df['liver_firm'].mode()[0], inplace = True)\n",
    "df['spleen_palpable'].fillna(df['spleen_palpable'].mode()[0], inplace = True)\n",
    "df['spiders'].fillna(df['spiders'].mode()[0], inplace = True)\n",
    "df['ascites'].fillna(df['ascites'].mode()[0], inplace = True)\n",
    "df['varices'].fillna(df['varices'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['bilirubin'].fillna(df['bilirubin'].mean(), inplace = True)\n",
    "df['alk_phosphate'].fillna(df['alk_phosphate'].mean(), inplace = True)\n",
    "df['sgot'].fillna(df['sgot'].mean(), inplace = True)\n",
    "df['protime'].fillna(df['protime'].mean(), inplace = True)\n",
    "df['histology'].fillna(df['histology'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['albumin'].fillna(df['albumin'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  int64\n",
       "sex                 object\n",
       "steroid               bool\n",
       "antivirals            bool\n",
       "fatigue               bool\n",
       "malaise               bool\n",
       "anorexia              bool\n",
       "liver_big             bool\n",
       "liver_firm            bool\n",
       "spleen_palpable       bool\n",
       "spiders               bool\n",
       "ascites               bool\n",
       "varices               bool\n",
       "bilirubin          float64\n",
       "alk_phosphate      float64\n",
       "sgot               float64\n",
       "albumin            float64\n",
       "protime            float64\n",
       "histology             bool\n",
       "class               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>steroid</th>\n",
       "      <th>antivirals</th>\n",
       "      <th>fatigue</th>\n",
       "      <th>malaise</th>\n",
       "      <th>anorexia</th>\n",
       "      <th>liver_big</th>\n",
       "      <th>liver_firm</th>\n",
       "      <th>spleen_palpable</th>\n",
       "      <th>spiders</th>\n",
       "      <th>ascites</th>\n",
       "      <th>varices</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>alk_phosphate</th>\n",
       "      <th>sgot</th>\n",
       "      <th>albumin</th>\n",
       "      <th>protime</th>\n",
       "      <th>histology</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>52.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>200.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.427517</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>85.89404</td>\n",
       "      <td>3.817266</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>False</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>85.89404</td>\n",
       "      <td>3.817266</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>120.00000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>249.00000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>41</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>144.00000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>47</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.427517</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>3.817266</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>38</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>89.00000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>66</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>53.00000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>166.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>38</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>male</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>98.00000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>42</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>46.00000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>49</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>58</td>\n",
       "      <td>male</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>55.00000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>58.00000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>34</td>\n",
       "      <td>male</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>28</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>50</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>75.00000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>54</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>92.00000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>57</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>55.00000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>54</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>101.00000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>True</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>48</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>278.00000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>72</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>52.00000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>38</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>49.00000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>25</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>181.00000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>38</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>140.00000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>47</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>36</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>54</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>49</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>70.00000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>114.00000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>True</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>173.00000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>41</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>120.00000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>True</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>70</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>528.00000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>20</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>152.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>36</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>46</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>105.325397</td>\n",
       "      <td>242.00000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>44</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>142.00000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>61.852273</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>53</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>43</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age     sex  steroid  antivirals  fatigue  malaise  anorexia  liver_big  \\\n",
       "0     30    male    False       False    False    False     False      False   \n",
       "1     50  female    False       False     True    False     False      False   \n",
       "2     78  female     True       False     True    False     False       True   \n",
       "3     31  female     True        True    False    False     False       True   \n",
       "4     34  female     True       False    False    False     False       True   \n",
       "5     34  female     True       False    False    False     False       True   \n",
       "6     51  female    False       False     True    False      True       True   \n",
       "7     23  female     True       False    False    False     False       True   \n",
       "8     39  female     True       False     True    False     False       True   \n",
       "9     30  female     True       False    False    False     False       True   \n",
       "10    39  female    False        True    False    False     False      False   \n",
       "11    32  female     True        True     True    False     False       True   \n",
       "12    41  female     True        True     True    False     False       True   \n",
       "13    30  female     True       False     True    False     False       True   \n",
       "14    47  female    False        True    False    False     False       True   \n",
       "15    38  female    False       False     True     True      True       True   \n",
       "16    66  female     True       False     True    False     False       True   \n",
       "17    40  female    False       False     True    False     False       True   \n",
       "18    38  female     True       False    False    False     False       True   \n",
       "19    38  female    False        True    False    False     False      False   \n",
       "20    22    male     True        True     True    False     False       True   \n",
       "21    27  female     True       False     True     True      True      False   \n",
       "22    31  female     True       False    False    False     False       True   \n",
       "23    42  female     True       False    False    False     False       True   \n",
       "24    25    male    False        True    False    False     False       True   \n",
       "25    27  female    False       False     True     True     False       True   \n",
       "26    49  female    False        True     True     True      True       True   \n",
       "27    58    male     True       False     True    False     False       True   \n",
       "28    61  female    False       False     True    False     False      False   \n",
       "29    51  female    False        True     True     True     False       True   \n",
       "..   ...     ...      ...         ...      ...      ...       ...        ...   \n",
       "125   34    male     True       False     True     True      True      False   \n",
       "126   28  female     True       False     True     True      True       True   \n",
       "127   50  female     True       False     True    False     False       True   \n",
       "128   54  female    False       False     True     True     False       True   \n",
       "129   57  female    False       False     True     True     False       True   \n",
       "130   54  female     True       False    False    False     False       True   \n",
       "131   31  female    False       False     True     True      True       True   \n",
       "132   48  female     True       False     True     True      True       True   \n",
       "133   72  female     True        True     True    False     False       True   \n",
       "134   38  female    False       False    False    False     False       True   \n",
       "135   25  female     True       False     True    False     False      False   \n",
       "136   51  female     True       False    False    False     False      False   \n",
       "137   38  female     True       False    False    False     False       True   \n",
       "138   47  female     True       False     True     True     False       True   \n",
       "139   45  female     True        True    False    False     False       True   \n",
       "140   36  female    False       False     True     True      True      False   \n",
       "141   54  female    False       False     True     True     False       True   \n",
       "142   51  female     True       False     True    False     False       True   \n",
       "143   49  female    False       False     True     True     False       True   \n",
       "144   45  female     True       False     True     True      True       True   \n",
       "145   31  female    False       False     True    False     False       True   \n",
       "146   41  female     True       False     True    False     False       True   \n",
       "147   70  female    False       False     True     True      True       True   \n",
       "148   20  female    False       False    False    False     False       True   \n",
       "149   36  female     True       False    False    False     False       True   \n",
       "150   46  female     True       False     True     True      True       True   \n",
       "151   44  female     True       False     True    False     False       True   \n",
       "152   61  female    False       False     True     True     False      False   \n",
       "153   53    male    False       False     True    False     False       True   \n",
       "154   43  female     True       False     True    False     False       True   \n",
       "\n",
       "     liver_firm  spleen_palpable  spiders  ascites  varices  bilirubin  \\\n",
       "0         False            False    False    False    False   1.000000   \n",
       "1         False            False    False    False    False   0.900000   \n",
       "2         False            False    False    False    False   0.700000   \n",
       "3         False            False    False    False    False   0.700000   \n",
       "4         False            False    False    False    False   1.000000   \n",
       "5         False            False    False    False    False   0.900000   \n",
       "6         False             True     True    False    False   1.427517   \n",
       "7         False            False    False    False    False   1.000000   \n",
       "8          True            False    False    False    False   0.700000   \n",
       "9         False            False    False    False    False   1.000000   \n",
       "10         True            False    False    False    False   1.300000   \n",
       "11         True            False     True    False    False   1.000000   \n",
       "12         True            False    False    False    False   0.900000   \n",
       "13         True            False    False    False    False   2.200000   \n",
       "14        False            False    False    False    False   1.427517   \n",
       "15        False            False    False     True    False   2.000000   \n",
       "16        False            False    False    False    False   1.200000   \n",
       "17         True            False    False    False    False   0.600000   \n",
       "18        False            False    False    False    False   0.700000   \n",
       "19         True            False    False    False    False   0.700000   \n",
       "20        False            False    False    False    False   0.900000   \n",
       "21         True             True     True    False    False   1.200000   \n",
       "22        False            False    False    False    False   1.000000   \n",
       "23        False            False    False    False    False   0.900000   \n",
       "24        False            False    False    False    False   0.400000   \n",
       "25        False            False    False    False    False   0.800000   \n",
       "26         True            False     True    False    False   0.600000   \n",
       "27         True            False     True    False    False   1.400000   \n",
       "28         True            False    False    False    False   1.300000   \n",
       "29        False            False    False    False    False   1.000000   \n",
       "..          ...              ...      ...      ...      ...        ...   \n",
       "125        True            False     True    False    False   0.700000   \n",
       "126       False            False     True     True    False   1.000000   \n",
       "127        True             True    False     True     True   2.800000   \n",
       "128       False            False    False     True    False   1.200000   \n",
       "129       False            False     True     True    False   4.600000   \n",
       "130       False            False    False    False    False   1.000000   \n",
       "131       False             True    False    False    False   8.000000   \n",
       "132        True            False     True    False    False   2.000000   \n",
       "133        True            False    False    False    False   1.000000   \n",
       "134        True            False    False    False    False   0.400000   \n",
       "135        True             True     True     True     True   1.300000   \n",
       "136        True            False     True    False    False   0.800000   \n",
       "137        True            False     True    False     True   1.600000   \n",
       "138        True            False     True     True     True   1.000000   \n",
       "139       False            False    False    False    False   1.300000   \n",
       "140        True            False     True    False     True   1.700000   \n",
       "141       False             True    False     True    False   3.900000   \n",
       "142        True             True     True    False     True   1.000000   \n",
       "143       False             True     True    False    False   1.400000   \n",
       "144       False            False     True     True    False   1.900000   \n",
       "145       False            False    False    False    False   1.200000   \n",
       "146        True             True     True    False     True   4.200000   \n",
       "147       False            False    False    False    False   1.700000   \n",
       "148       False            False    False    False    False   0.900000   \n",
       "149       False            False    False    False    False   0.600000   \n",
       "150       False            False     True     True     True   7.600000   \n",
       "151        True            False    False    False    False   0.900000   \n",
       "152        True            False     True    False    False   0.800000   \n",
       "153       False             True     True    False     True   1.500000   \n",
       "154       False             True     True     True    False   1.200000   \n",
       "\n",
       "     alk_phosphate       sgot   albumin     protime  histology class  \n",
       "0        85.000000   18.00000  4.000000   61.852273      False  live  \n",
       "1       135.000000   42.00000  3.500000   61.852273      False  live  \n",
       "2        96.000000   32.00000  4.000000   61.852273      False  live  \n",
       "3        46.000000   52.00000  4.000000   80.000000      False  live  \n",
       "4       105.325397  200.00000  4.000000   61.852273      False  live  \n",
       "5        95.000000   28.00000  4.000000   75.000000      False  live  \n",
       "6       105.325397   85.89404  3.817266   61.852273      False   die  \n",
       "7       105.325397   85.89404  3.817266   61.852273      False  live  \n",
       "8       105.325397   48.00000  4.400000   61.852273      False  live  \n",
       "9       105.325397  120.00000  3.900000   61.852273      False  live  \n",
       "10       78.000000   30.00000  4.400000   85.000000      False  live  \n",
       "11       59.000000  249.00000  3.700000   54.000000      False  live  \n",
       "12       81.000000   60.00000  3.900000   52.000000      False  live  \n",
       "13       57.000000  144.00000  4.900000   78.000000      False  live  \n",
       "14      105.325397   60.00000  3.817266   61.852273      False  live  \n",
       "15       72.000000   89.00000  2.900000   46.000000      False  live  \n",
       "16      102.000000   53.00000  4.300000   61.852273      False  live  \n",
       "17       62.000000  166.00000  4.000000   63.000000      False  live  \n",
       "18       53.000000   42.00000  4.100000   85.000000       True  live  \n",
       "19       70.000000   28.00000  4.200000   62.000000      False  live  \n",
       "20       48.000000   20.00000  4.200000   64.000000      False  live  \n",
       "21      133.000000   98.00000  4.100000   39.000000      False  live  \n",
       "22       85.000000   20.00000  4.000000  100.000000      False  live  \n",
       "23       60.000000   63.00000  4.700000   47.000000      False  live  \n",
       "24       45.000000   18.00000  4.300000   70.000000      False  live  \n",
       "25       95.000000   46.00000  3.800000  100.000000      False  live  \n",
       "26       85.000000   48.00000  3.700000   61.852273      False  live  \n",
       "27      175.000000   55.00000  2.700000   36.000000      False  live  \n",
       "28       78.000000   25.00000  3.800000  100.000000      False  live  \n",
       "29       78.000000   58.00000  4.600000   52.000000      False  live  \n",
       "..             ...        ...       ...         ...        ...   ...  \n",
       "125      70.000000   24.00000  4.100000  100.000000       True  live  \n",
       "126     105.325397   20.00000  4.000000   61.852273       True  live  \n",
       "127     155.000000   75.00000  2.400000   32.000000       True   die  \n",
       "128      85.000000   92.00000  3.100000   66.000000       True  live  \n",
       "129      82.000000   55.00000  3.300000   30.000000       True   die  \n",
       "130      85.000000   30.00000  4.500000    0.000000       True  live  \n",
       "131     105.325397  101.00000  2.200000   61.852273       True   die  \n",
       "132     158.000000  278.00000  3.800000   61.852273       True  live  \n",
       "133     115.000000   52.00000  3.400000   50.000000       True  live  \n",
       "134     243.000000   49.00000  3.800000   90.000000       True   die  \n",
       "135     181.000000  181.00000  4.500000   57.000000       True  live  \n",
       "136     105.325397   33.00000  4.500000   61.852273       True  live  \n",
       "137     130.000000  140.00000  3.500000   56.000000       True  live  \n",
       "138     166.000000   30.00000  2.600000   31.000000       True   die  \n",
       "139      85.000000   44.00000  4.200000   85.000000       True  live  \n",
       "140     295.000000   60.00000  2.700000   61.852273       True  live  \n",
       "141     120.000000   28.00000  3.500000   43.000000       True   die  \n",
       "142     105.325397   20.00000  3.000000   63.000000       True  live  \n",
       "143      85.000000   70.00000  3.500000   35.000000       True   die  \n",
       "144     105.325397  114.00000  2.400000   61.852273       True   die  \n",
       "145      75.000000  173.00000  4.200000   54.000000       True  live  \n",
       "146      65.000000  120.00000  3.400000   61.852273       True   die  \n",
       "147     109.000000  528.00000  2.800000   35.000000       True   die  \n",
       "148      89.000000  152.00000  4.000000   61.852273       True  live  \n",
       "149     120.000000   30.00000  4.000000   61.852273       True  live  \n",
       "150     105.325397  242.00000  3.300000   50.000000       True   die  \n",
       "151     126.000000  142.00000  4.300000   61.852273       True  live  \n",
       "152      75.000000   20.00000  4.100000   61.852273       True  live  \n",
       "153      81.000000   19.00000  4.100000   48.000000       True  live  \n",
       "154     100.000000   19.00000  3.100000   42.000000       True   die  \n",
       "\n",
       "[155 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUMMY VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_new = pd.get_dummies(df, columns=['sex','steroid','antivirals','fatigue',\n",
    "                                         'malaise','anorexia',\n",
    "                                         'liver_big','liver_firm',\n",
    "                                         'spleen_palpable','spiders',\n",
    "                                         'ascites','varices','histology' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                        int64\n",
       "bilirubin                float64\n",
       "alk_phosphate            float64\n",
       "sgot                     float64\n",
       "albumin                  float64\n",
       "protime                  float64\n",
       "class                     object\n",
       "sex_female                 uint8\n",
       "sex_male                   uint8\n",
       "steroid_False              uint8\n",
       "steroid_True               uint8\n",
       "antivirals_False           uint8\n",
       "antivirals_True            uint8\n",
       "fatigue_False              uint8\n",
       "fatigue_True               uint8\n",
       "malaise_False              uint8\n",
       "malaise_True               uint8\n",
       "anorexia_False             uint8\n",
       "anorexia_True              uint8\n",
       "liver_big_False            uint8\n",
       "liver_big_True             uint8\n",
       "liver_firm_False           uint8\n",
       "liver_firm_True            uint8\n",
       "spleen_palpable_False      uint8\n",
       "spleen_palpable_True       uint8\n",
       "spiders_False              uint8\n",
       "spiders_True               uint8\n",
       "ascites_False              uint8\n",
       "ascites_True               uint8\n",
       "varices_False              uint8\n",
       "varices_True               uint8\n",
       "histology_False            uint8\n",
       "histology_True             uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_y = pd.DataFrame(data_new['class'])\n",
    "data_X = data_new.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLYING MODEL SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.9354838709677419\n",
      "[[ 3  1]\n",
      " [ 1 26]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.75      0.75      0.75         4\n",
      "       live       0.96      0.96      0.96        27\n",
      "\n",
      "avg / total       0.94      0.94      0.94        31\n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.9354838709677419\n",
      "[[ 2  2]\n",
      " [ 0 27]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       1.00      0.50      0.67         4\n",
      "       live       0.93      1.00      0.96        27\n",
      "\n",
      "avg / total       0.94      0.94      0.93        31\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8709677419354839\n",
      "[[ 0  4]\n",
      " [ 0 27]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.00      0.00      0.00         4\n",
      "       live       0.87      1.00      0.93        27\n",
      "\n",
      "avg / total       0.76      0.87      0.81        31\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8064516129032258\n",
      "[[ 1  3]\n",
      " [ 3 24]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.25      0.25      0.25         4\n",
      "       live       0.89      0.89      0.89        27\n",
      "\n",
      "avg / total       0.81      0.81      0.81        31\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8709677419354839\n",
      "[[ 0  4]\n",
      " [ 0 27]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.00      0.00      0.00         4\n",
      "       live       0.87      1.00      0.93        27\n",
      "\n",
      "avg / total       0.76      0.87      0.81        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = (SVC(kernel='linear'),\n",
    "          LinearSVC(),\n",
    "          SVC(kernel='rbf'),\n",
    "          SVC(kernel='poly'),\n",
    "          SVC(kernel='sigmoid'))\n",
    "\n",
    "for clf in models:\n",
    "    print(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "   \n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # New line\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=5, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.9032258064516129\n",
      "[[ 4  0]\n",
      " [ 3 24]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.57      1.00      0.73         4\n",
      "       live       1.00      0.89      0.94        27\n",
      "\n",
      "avg / total       0.94      0.90      0.91        31\n",
      "\n",
      "LinearSVC(C=0.5, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=5, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.9354838709677419\n",
      "[[ 3  1]\n",
      " [ 1 26]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.75      0.75      0.75         4\n",
      "       live       0.96      0.96      0.96        27\n",
      "\n",
      "avg / total       0.94      0.94      0.94        31\n",
      "\n",
      "SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=5, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8387096774193549\n",
      "[[ 0  4]\n",
      " [ 1 26]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.00      0.00      0.00         4\n",
      "       live       0.87      0.96      0.91        27\n",
      "\n",
      "avg / total       0.75      0.84      0.79        31\n",
      "\n",
      "SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=5, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8064516129032258\n",
      "[[ 1  3]\n",
      " [ 3 24]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.25      0.25      0.25         4\n",
      "       live       0.89      0.89      0.89        27\n",
      "\n",
      "avg / total       0.81      0.81      0.81        31\n",
      "\n",
      "SVC(C=0.5, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=5, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.12903225806451613\n",
      "[[ 4  0]\n",
      " [27  0]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.13      1.00      0.23         4\n",
      "       live       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.02      0.13      0.03        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = (SVC(kernel='linear',random_state=5,C=0.5,class_weight = \"balanced\"),\n",
    "          LinearSVC(random_state=5,C=0.5,class_weight = \"balanced\"),\n",
    "          SVC(kernel='rbf', random_state=5,C=0.5,class_weight = \"balanced\"),\n",
    "          SVC(kernel='poly',random_state=5, C=0.5,class_weight = \"balanced\"),\n",
    "          SVC(kernel='sigmoid',random_state=5,C=0.5,class_weight = \"balanced\"))\n",
    "\n",
    "for clf in models:\n",
    "    print(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # New line\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.7, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.9354838709677419\n",
      "[[ 3  1]\n",
      " [ 1 26]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.75      0.75      0.75         4\n",
      "       live       0.96      0.96      0.96        27\n",
      "\n",
      "avg / total       0.94      0.94      0.94        31\n",
      "\n",
      "LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.8064516129032258\n",
      "[[ 4  0]\n",
      " [ 6 21]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.40      1.00      0.57         4\n",
      "       live       1.00      0.78      0.88        27\n",
      "\n",
      "avg / total       0.92      0.81      0.84        31\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.7, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8709677419354839\n",
      "[[ 0  4]\n",
      " [ 0 27]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.00      0.00      0.00         4\n",
      "       live       0.87      1.00      0.93        27\n",
      "\n",
      "avg / total       0.76      0.87      0.81        31\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.7, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8064516129032258\n",
      "[[ 1  3]\n",
      " [ 3 24]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.25      0.25      0.25         4\n",
      "       live       0.89      0.89      0.89        27\n",
      "\n",
      "avg / total       0.81      0.81      0.81        31\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.7, kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8709677419354839\n",
      "[[ 0  4]\n",
      " [ 0 27]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.00      0.00      0.00         4\n",
      "       live       0.87      1.00      0.93        27\n",
      "\n",
      "avg / total       0.76      0.87      0.81        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = (SVC(kernel='linear',gamma=0.7),\n",
    "          LinearSVC(C=0.5),\n",
    "          SVC(kernel='rbf', gamma=0.7),\n",
    "          SVC(kernel='poly', gamma=0.7),\n",
    "         SVC(kernel='sigmoid', gamma=0.7))\n",
    "\n",
    "for clf in models:\n",
    "    print(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # New line\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.1, verbose=False)\n",
      "0.9032258064516129\n",
      "[[ 4  0]\n",
      " [ 3 24]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.57      1.00      0.73         4\n",
      "       live       1.00      0.89      0.94        27\n",
      "\n",
      "avg / total       0.94      0.90      0.91        31\n",
      "\n",
      "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.1,\n",
      "     verbose=0)\n",
      "0.9032258064516129\n",
      "[[ 3  1]\n",
      " [ 2 25]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.60      0.75      0.67         4\n",
      "       live       0.96      0.93      0.94        27\n",
      "\n",
      "avg / total       0.91      0.90      0.91        31\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.1, verbose=False)\n",
      "0.8387096774193549\n",
      "[[ 0  4]\n",
      " [ 1 26]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.00      0.00      0.00         4\n",
      "       live       0.87      0.96      0.91        27\n",
      "\n",
      "avg / total       0.75      0.84      0.79        31\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.1, verbose=False)\n",
      "0.8064516129032258\n",
      "[[ 1  3]\n",
      " [ 3 24]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.25      0.25      0.25         4\n",
      "       live       0.89      0.89      0.89        27\n",
      "\n",
      "avg / total       0.81      0.81      0.81        31\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.1, verbose=False)\n",
      "0.12903225806451613\n",
      "[[ 4  0]\n",
      " [27  0]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.13      1.00      0.23         4\n",
      "       live       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.02      0.13      0.03        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = (SVC(kernel='linear', tol=0.1,class_weight = \"balanced\"),\n",
    "          LinearSVC(tol=0.1,class_weight = \"balanced\"),\n",
    "          SVC(kernel='rbf', tol=0.1,class_weight = \"balanced\"),\n",
    "          SVC(kernel='poly',tol=0.1,class_weight = \"balanced\"),\n",
    "          SVC(kernel='sigmoid',tol=0.1,class_weight = \"balanced\"))\n",
    "\n",
    "for clf in models:\n",
    "    print(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # New line\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING DROPNA():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = test_df.dropna()\n",
    "data_d = pd.get_dummies(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                        int64\n",
       "antivirals                  bool\n",
       "bilirubin                float64\n",
       "alk_phosphate            float64\n",
       "sgot                     float64\n",
       "albumin                  float64\n",
       "protime                  float64\n",
       "histology                   bool\n",
       "sex_female                 uint8\n",
       "sex_male                   uint8\n",
       "steroid_False              uint8\n",
       "steroid_True               uint8\n",
       "fatigue_False              uint8\n",
       "fatigue_True               uint8\n",
       "malaise_False              uint8\n",
       "malaise_True               uint8\n",
       "anorexia_False             uint8\n",
       "anorexia_True              uint8\n",
       "liver_big_False            uint8\n",
       "liver_big_True             uint8\n",
       "liver_firm_False           uint8\n",
       "liver_firm_True            uint8\n",
       "spleen_palpable_False      uint8\n",
       "spleen_palpable_True       uint8\n",
       "spiders_False              uint8\n",
       "spiders_True               uint8\n",
       "ascites_False              uint8\n",
       "ascites_True               uint8\n",
       "varices_False              uint8\n",
       "varices_True               uint8\n",
       "class_die                  uint8\n",
       "class_live                 uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_d.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPYING MODEL ON ONLY (TYPE WHICH ARE BOOL & OBJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = data_d.loc[:, 'age':'varices_True'].values \n",
    "output_data = test_df['class']\n",
    "output_data = output_data.values\n",
    "y = [1 if i == 'live' else -1 for i in output_data] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 30)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8125\n",
      "[[ 3  1]\n",
      " [ 2 10]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.75      0.67         4\n",
      "          1       0.91      0.83      0.87        12\n",
      "\n",
      "avg / total       0.83      0.81      0.82        16\n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.8125\n",
      "[[ 1  3]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      0.25      0.40         4\n",
      "          1       0.80      1.00      0.89        12\n",
      "\n",
      "avg / total       0.85      0.81      0.77        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.6875\n",
      "[[2 2]\n",
      " [3 9]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.40      0.50      0.44         4\n",
      "          1       0.82      0.75      0.78        12\n",
      "\n",
      "avg / total       0.71      0.69      0.70        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = (SVC(kernel='linear'),\n",
    "          LinearSVC(),\n",
    "          SVC(kernel='rbf'),\n",
    "          SVC(kernel='poly'),\n",
    "          SVC(kernel='sigmoid'))\n",
    "\n",
    "for clf in models:\n",
    "    print(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # New line\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=5, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8125\n",
      "[[ 3  1]\n",
      " [ 2 10]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.75      0.67         4\n",
      "          1       0.91      0.83      0.87        12\n",
      "\n",
      "avg / total       0.83      0.81      0.82        16\n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=5, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=5, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=5, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.6875\n",
      "[[2 2]\n",
      " [3 9]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.40      0.50      0.44         4\n",
      "          1       0.82      0.75      0.78        12\n",
      "\n",
      "avg / total       0.71      0.69      0.70        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=5, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = (SVC(kernel='linear',random_state=5),\n",
    "          LinearSVC(random_state=5),\n",
    "          SVC(kernel='rbf', random_state=5),\n",
    "          SVC(kernel='poly',random_state=5, degree=3),\n",
    "          SVC(kernel='sigmoid',random_state=5))\n",
    "\n",
    "for clf in models:\n",
    "    print(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # New line\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8125\n",
      "[[ 1  3]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      0.25      0.40         4\n",
      "          1       0.80      1.00      0.89        12\n",
      "\n",
      "avg / total       0.85      0.81      0.77        16\n",
      "\n",
      "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.6875\n",
      "[[3 1]\n",
      " [4 8]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.43      0.75      0.55         4\n",
      "          1       0.89      0.67      0.76        12\n",
      "\n",
      "avg / total       0.77      0.69      0.71        16\n",
      "\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.6875\n",
      "[[2 2]\n",
      " [3 9]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.40      0.50      0.44         4\n",
      "          1       0.82      0.75      0.78        12\n",
      "\n",
      "avg / total       0.71      0.69      0.70        16\n",
      "\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = (SVC(kernel='linear', C=0.1),\n",
    "          LinearSVC(C=0.1),\n",
    "          SVC(kernel='rbf', C=0.1),\n",
    "          SVC(kernel='poly', C=0.1),\n",
    "         SVC(kernel='sigmoid', C=0.1))\n",
    "\n",
    "for clf in models:\n",
    "    print(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # New line\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.7, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8125\n",
      "[[ 3  1]\n",
      " [ 2 10]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.75      0.67         4\n",
      "          1       0.91      0.83      0.87        12\n",
      "\n",
      "avg / total       0.83      0.81      0.82        16\n",
      "\n",
      "LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.8125\n",
      "[[ 3  1]\n",
      " [ 2 10]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.75      0.67         4\n",
      "          1       0.91      0.83      0.87        12\n",
      "\n",
      "avg / total       0.83      0.81      0.82        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.7, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.7, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.6875\n",
      "[[2 2]\n",
      " [3 9]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.40      0.50      0.44         4\n",
      "          1       0.82      0.75      0.78        12\n",
      "\n",
      "avg / total       0.71      0.69      0.70        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.7, kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = (SVC(kernel='linear',gamma=0.7),\n",
    "          LinearSVC(C=0.5),\n",
    "          SVC(kernel='rbf', gamma=0.7),\n",
    "          SVC(kernel='poly', gamma=0.7),\n",
    "         SVC(kernel='sigmoid', gamma=0.7))\n",
    "\n",
    "for clf in models:\n",
    "    print(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # New line\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPYING MODEL AFTER USING DROPNA() METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                        int64\n",
       "antivirals                  bool\n",
       "bilirubin                float64\n",
       "alk_phosphate            float64\n",
       "sgot                     float64\n",
       "albumin                  float64\n",
       "protime                  float64\n",
       "histology                   bool\n",
       "sex_female                 uint8\n",
       "sex_male                   uint8\n",
       "steroid_False              uint8\n",
       "steroid_True               uint8\n",
       "fatigue_False              uint8\n",
       "fatigue_True               uint8\n",
       "malaise_False              uint8\n",
       "malaise_True               uint8\n",
       "anorexia_False             uint8\n",
       "anorexia_True              uint8\n",
       "liver_big_False            uint8\n",
       "liver_big_True             uint8\n",
       "liver_firm_False           uint8\n",
       "liver_firm_True            uint8\n",
       "spleen_palpable_False      uint8\n",
       "spleen_palpable_True       uint8\n",
       "spiders_False              uint8\n",
       "spiders_True               uint8\n",
       "ascites_False              uint8\n",
       "ascites_True               uint8\n",
       "varices_False              uint8\n",
       "varices_True               uint8\n",
       "class_die                  uint8\n",
       "class_live                 uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_d.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = data_d.loc[:, 'age':].values \n",
    "output_data = test_df['class']\n",
    "output_data = output_data.values\n",
    "y = [1 if i == 'live' else -1 for i in output_data] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "1.0\n",
      "[[ 4  0]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      1.00      1.00         4\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        16\n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.9375\n",
      "[[ 3  1]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      0.75      0.86         4\n",
      "          1       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.94      0.94      0.93        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8125\n",
      "[[ 3  1]\n",
      " [ 2 10]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.75      0.67         4\n",
      "          1       0.91      0.83      0.87        12\n",
      "\n",
      "avg / total       0.83      0.81      0.82        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = (SVC(kernel='linear'),\n",
    "          LinearSVC(),\n",
    "          SVC(kernel='rbf'),\n",
    "          SVC(kernel='poly'),\n",
    "          SVC(kernel='sigmoid'))\n",
    "\n",
    "for clf in models:\n",
    "    print(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # New line\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=5, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "1.0\n",
      "[[ 4  0]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      1.00      1.00         4\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        16\n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=5, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.9375\n",
      "[[ 3  1]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      0.75      0.86         4\n",
      "          1       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.94      0.94      0.93        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=5, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=5, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8125\n",
      "[[ 3  1]\n",
      " [ 2 10]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.75      0.67         4\n",
      "          1       0.91      0.83      0.87        12\n",
      "\n",
      "avg / total       0.83      0.81      0.82        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=5, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = (SVC(kernel='linear',random_state=5),\n",
    "          LinearSVC(random_state=5),\n",
    "          SVC(kernel='rbf', random_state=5),\n",
    "          SVC(kernel='poly',random_state=5, degree=3),\n",
    "          SVC(kernel='sigmoid',random_state=5))\n",
    "\n",
    "for clf in models:\n",
    "    print(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # New line\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.9375\n",
      "[[ 3  1]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      0.75      0.86         4\n",
      "          1       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.94      0.94      0.93        16\n",
      "\n",
      "LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.875\n",
      "[[ 3  1]\n",
      " [ 1 11]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.75      0.75      0.75         4\n",
      "          1       0.92      0.92      0.92        12\n",
      "\n",
      "avg / total       0.88      0.88      0.88        16\n",
      "\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8125\n",
      "[[ 3  1]\n",
      " [ 2 10]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.75      0.67         4\n",
      "          1       0.91      0.83      0.87        12\n",
      "\n",
      "avg / total       0.83      0.81      0.82        16\n",
      "\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = (SVC(kernel='linear', C=0.1),\n",
    "          LinearSVC(C=0.1),\n",
    "          SVC(kernel='rbf', C=0.1),\n",
    "          SVC(kernel='poly', C=0.1),\n",
    "         SVC(kernel='sigmoid', C=0.1))\n",
    "\n",
    "for clf in models:\n",
    "    print(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # New line\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.7, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "1.0\n",
      "[[ 4  0]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      1.00      1.00         4\n",
      "          1       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        16\n",
      "\n",
      "LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.9375\n",
      "[[ 3  1]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      0.75      0.86         4\n",
      "          1       0.92      1.00      0.96        12\n",
      "\n",
      "avg / total       0.94      0.94      0.93        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.7, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.7, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8125\n",
      "[[ 3  1]\n",
      " [ 2 10]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.75      0.67         4\n",
      "          1       0.91      0.83      0.87        12\n",
      "\n",
      "avg / total       0.83      0.81      0.82        16\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.7, kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.75\n",
      "[[ 0  4]\n",
      " [ 0 12]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00         4\n",
      "          1       0.75      1.00      0.86        12\n",
      "\n",
      "avg / total       0.56      0.75      0.64        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = (SVC(kernel='linear',gamma=0.7),\n",
    "          LinearSVC(C=0.5),\n",
    "          SVC(kernel='rbf', gamma=0.7),\n",
    "          SVC(kernel='poly', gamma=0.7),\n",
    "         SVC(kernel='sigmoid', gamma=0.7))\n",
    "\n",
    "for clf in models:\n",
    "    print(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # New line\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 0.1, 'gamma': 0.1} with a score of 0.83\n",
      "The best parameters are {'C': 0.1, 'gamma': 0.1} with a score of 0.80\n",
      "The best parameters are {'C': 0.1, 'gamma': 0.1} with a score of 0.75\n",
      "The best parameters are {'C': 0.1, 'gamma': 0.1} with a score of 0.80\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#C_range = (np.logspace(-2, 10, 13))\n",
    "#gamma_range = np.logspace(-9, 3, 13)\n",
    "C_range = np.arange(0.1,2.5,0.1)\n",
    "gamma_range = np.arange(0.1,1,0.1) \n",
    "#print(C_range)\n",
    "#print(gamma_range)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2)\n",
    "grid = GridSearchCV(SVC(kernel='linear'), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "grid = GridSearchCV(SVC(kernel='rbf'), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "grid = GridSearchCV(SVC(kernel='poly'), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "grid = GridSearchCV(SVC(kernel='sigmoid'), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8387096774193549\n",
      "[[ 3  4]\n",
      " [ 1 23]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.75      0.43      0.55         7\n",
      "       live       0.85      0.96      0.90        24\n",
      "\n",
      "avg / total       0.83      0.84      0.82        31\n",
      "\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.7741935483870968\n",
      "[[ 0  7]\n",
      " [ 0 24]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.00      0.00      0.00         7\n",
      "       live       0.77      1.00      0.87        24\n",
      "\n",
      "avg / total       0.60      0.77      0.68        31\n",
      "\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.8064516129032258\n",
      "[[ 5  2]\n",
      " [ 4 20]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.56      0.71      0.63         7\n",
      "       live       0.91      0.83      0.87        24\n",
      "\n",
      "avg / total       0.83      0.81      0.81        31\n",
      "\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.7741935483870968\n",
      "[[ 0  7]\n",
      " [ 0 24]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        die       0.00      0.00      0.00         7\n",
      "       live       0.77      1.00      0.87        24\n",
      "\n",
      "avg / total       0.60      0.77      0.68        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "models = ( (SVC(kernel='linear', C=0.1,gamma=0.1),\n",
    "          SVC(kernel='rbf', C=0.1,gamma=0.1),\n",
    "          SVC(kernel='poly', C=0.1,gamma=0.1),\n",
    "         SVC(kernel='sigmoid', C=0.1,gamma=0.1)))\n",
    "\n",
    "for clf in models:\n",
    "    print(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # New line\n",
    "    print('\\n')\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
